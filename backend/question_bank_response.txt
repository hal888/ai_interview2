```json
{
    "questions": [
        {
            "id": 1,
            "content": "请简要介绍一下你的职业经历，并重点说明你是如何从Java后端开发转向大数据领域的。",
            "type": "高频必问题",
            "answer": "建议按时间线概述工作经历，突出技术栈的演进。重点阐述在传易音乐期间，面对业务数据量激增（从万级到亿级）的挑战，如何主动或被动地承担起数据平台建设的职责，从而完成了从后端开发到大数据架构师的转型。可以提及对Spark、Flink等大数据技术的学习路径和应用实践。",
            "analysis": "考察候选人的职业发展路径、转型动机与能力，以及对自己职业历程的清晰认知和总结能力。"
        },
        {
            "id": 2,
            "content": "在Boomplay项目中，你提到主导了Lambda架构的设计与落地。请详细说明你是如何权衡实时（Flink）与离线（Spark）处理路径的？在架构演进过程中遇到过哪些重大挑战，又是如何解决的？",
            "type": "简历深挖题",
            "answer": "建议从业务需求出发（如实时风控需要毫秒级响应，T+1报表可接受小时级延迟），结合数据量（日均40亿+）、数据一致性要求、开发维护成本、团队技术栈等因素进行权衡。挑战可能包括：实时与离线数据口径对齐、状态管理、Exactly-Once语义保证、资源调度冲突等。解决方案可提及使用Kafka作为统一数据源、设计可回溯的实时处理逻辑、优化Checkpoint机制、建立数据质量监控等。",
            "analysis": "深度考察候选人对主流大数据架构的深刻理解、技术选型的决策能力，以及在复杂项目中解决实际技术难题的经验和系统性思维。"
        },
        {
            "id": 3,
            "content": "你成功将大数据服务从AWS迁移至阿里云，并实现了60%的成本下降。请详细阐述这次迁移的核心决策过程、技术架构上的关键重构点，以及具体的成本优化策略。",
            "type": "简历深挖题",
            "answer": "决策过程：应分析迁移驱动因素（成本、服务、合规等），进行详细的TCO对比和风险评估。关键重构：可能涉及计算引擎从EMR到MaxCompute/自建集群的适配，存储从S3到OSS的迁移策略，数据同步工具的选择与开发，调度系统（如Airflow）的迁移或重构。成本优化策略：具体说明如何通过资源弹性伸缩（Spot实例/抢占式实例）、存储分层（热/温/冷数据）、计算优化（如Spark SQL优化、小文件合并）、数据压缩格式选择、闲置资源清理等手段实现降本。",
            "analysis": "重点考察候选人的云平台实践经验、大型系统迁移的项目管理能力、对基础设施成本的敏感度以及通过技术手段实现商业价值（降本增效）的能力。"
        },
        {
            "id": 4,
            "content": "在构建实时风控平台时，你提到使用Flink+Redis日均拦截150万+刷歌行为。请描述一下这个风控规则引擎的核心设计，例如规则是如何定义、管理和动态更新的？如何保证在高并发下的处理性能和低延迟？",
            "type": "专业技能题",
            "answer": "核心设计：可介绍规则的数据结构（如JSON或DSL），规则管理后台（用于增删改查和发布），规则加载到Flink Job的方式（如广播流）。动态更新：通过将规则存储在配置中心（如Redis/ZooKeeper），Flink作业监听变更并实时更新内存中的规则集。性能保障：阐述如何使用Flink的Keyed State或Operator State进行用户维度的聚合计算，利用Redis作为高性能的缓存或特征存储，通过合理的并行度和资源分配来保证吞吐，以及可能用到的窗口优化和异步IO。",
            "analysis": "考察候选人对实时计算框架（Flink）的实战应用能力，对复杂业务场景（风控）的抽象建模能力，以及对高并发、低延迟系统设计的掌握程度。"
        },
        {
            "id": 5,
            "content": "你主导设计了分层数仓模型（ODS→DWD→DWS→ADS）。请结合音乐流媒体业务（如用户听歌、搜索、收藏等行为），举例说明你是如何设计某一主题域（如“用户行为”）下的核心事实表和维度表的？如何确保数据模型能灵活支持未来的业务变化？",
            "type": "专业技能题",
            "answer": "举例：以“听歌行为”为例，DWD层事实表可包含：用户ID、歌曲ID、行为时间、行为类型（播放、收藏、分享）、播放时长、设备信息等字段。关联的维度表包括：用户维度表、歌曲维度表（关联艺人、专辑）、时间维度表、设备维度表。灵活性保障：采用维度建模，确保核心事实表稳定；使用缓慢变化维（SCD）处理维度属性变化；在DWS层构建宽表或主题聚合表以满足特定分析需求；建立清晰的字段扩展规范和元数据管理。",
            "analysis": "考察候选人的数据建模理论功底，将业务场景抽象为数据模型的能力，以及对数仓可扩展性和可维护性的设计思考。"
        },
        {
            "id": 6,
            "content": "你搭建了数据血缘可视化系统，覆盖90%+核心表。请说明这个系统是如何实现自动采集血缘关系的（例如，是从SQL解析、任务日志，还是其他方式）？它具体解决了数据团队在日常工作中的哪些痛点？",
            "type": "专业技能题",
            "answer": "实现方式：通常通过解析调度系统（如Airflow、DataWorks）的任务日志、解析Hive/Spark SQL的AST（抽象语法树）、或利用数据平台本身的元数据服务（如Hive Metastore Hook）来采集表和字段级别的依赖关系。解决的痛点：1. 影响分析：快速定位上游表故障对下游报表的影响范围。2. 变更管理：评估表结构变更或数据回溯的影响。3. 数据治理：辅助进行数据资产盘点、冗余表识别和下线。4. 问题排查：当数据异常时，沿血缘链路快速定位问题根源。",
            "analysis": "考察候选人对数据治理实践的理解深度，解决数据团队协作效率和数据质量问题的工程化思维，以及构建数据工具平台的实际经验。"
        },
        {
            "id": 7,
            "content": "在用户画像项目中，你通过Flink实现了标签的实时更新（延迟<10分钟）。请描述一个典型的实时标签（例如“高活跃用户”）的计算逻辑和更新流程。当实时标签与离线批量计算的标签结果出现不一致时，你会如何排查和处理？",
            "type": "专业技能题",
            "answer": "计算逻辑与流程：以“高活跃用户”为例，定义规则（如过去1小时播放歌曲数>10）。通过Flink消费用户行为事件流，按用户ID进行KeyBy，在滑动窗口或滚动窗口内进行计数聚合，达到阈值后实时输出标签更新事件到HBase/Redis。排查不一致：首先核对口径（时间窗口、行为定义、阈值）是否一致。然后检查数据源（实时流与离线T+1数据）是否一致。再检查处理逻辑（实时Flink作业逻辑 vs 离线Spark SQL逻辑）。最后检查数据更新时机（实时是准实时，离线有调度延迟）。处理方式：确定正确口径，修复有bug的一方，并建立定期对账任务监控差异。",
            "analysis": "考察候选人对实时数据应用场景的细节把握，对复杂数据处理流程中一致性问题的理解，以及系统化的问题排查和解决能力。"
        },
        {
            "id": 8,
            "content": "你拥有Java后端开发经验，现在又深耕大数据领域。你认为这两段经历对你当前担任大数据架构师的角色有哪些独特的优势？在处理大数据平台与后端业务系统的数据交互时，你的经验如何帮助你设计更合理的方案？",
            "type": "行为/情景题",
            "answer": "优势：1. 更理解数据产生端（业务系统）的架构、数据模型和痛点，能设计更合理的数据采集方案。2. 具备更强的系统设计、性能优化和故障排查能力，能更好地设计高可用、可扩展的大数据服务本身。3. 在技术选型时，能兼顾大数据组件与业务系统技术栈的整合成本。交互设计：会从API设计、异步消息（Kafka）解耦、数据格式约定（Protobuf/JSON Schema）、数据一致性（最终一致性）、监控告警一体化等方面进行综合考虑，避免给业务方带来过重负担，并保证数据链路的可靠性。",
            "analysis": "考察候选人跨领域经验的融合能力，能否将不同技术栈的经验转化为综合优势，以及从全局视角设计系统间协作方案的能力。"
        },
        {
            "id": 9,
            "content": "假设你加入我们公司，需要从零开始搭建一个数据平台。请描述你开展这项工作的首要步骤和关键里程碑规划。你会如何与业务、产品、运营等非技术团队协作，以确保平台建设能有效支撑业务目标？",
            "type": "行为/情景题",
            "answer": "首要步骤：1. 深入调研业务现状、核心痛点、数据需求及未来规划。2. 评估现有数据基础设施和数据资产。3. 制定初步的技术选型和架构蓝图。关键里程碑：1. 最小可行数据管道（MVP）：打通核心业务数据采集、存储和基础报表。2. 核心数仓主题建设：完成1-2个关键业务域（如用户、交易）的模型设计与应用。3. 数据产品化：交付首个数据产品（如核心驾驶舱、用户画像标签）。4. 平台化与治理：建立数据开发规范、质量监控和元数据管理。协作方式：定期沟通会、需求评审会、设立数据产品经理角色作为桥梁、提供自助数据查询工具、通过数据成果（报表、分析报告）展现价值，建立信任。",
            "analysis": "考察候选人的项目规划能力、从0到1的平台搭建方法论，以及至关重要的跨部门沟通协作和以业务价值为导向的思维模式。"
        },
        {
            "id": 10,
            "content": "在你的经历中，既有“搭建”新平台的高光时刻，也有“迁移”和“优化”现有系统的挑战。回顾你的职业生涯，你认为哪一次“优化”经历（无论是性能优化还是成本优化）最具挑战性？当时面临的核心矛盾是什么？你最终是如何破局的？",
            "type": "行为/情景题",
            "answer": "选择一次具体的优化经历（如云迁移成本优化、Spark作业性能优化、存储成本优化）。核心矛盾：可能是“业务快速发展要求资源快速扩张”与“严控成本预算”之间的矛盾，或是“优化改造需要停机/影响业务”与“保证服务SLA”之间的矛盾。破局方法：通过详细的数据分析和论证（如资源利用率报表、成本分摊模型）争取管理层支持；采用分阶段、灰度迁移的策略降低风险；通过技术创新（如使用更高效的压缩算法、计算下推）在提升性能的同时降低成本；建立长效的成本监控和优化机制。",
            "analysis": "通过具体案例考察候选人在面对复杂约束和矛盾时的解决问题能力、抗压能力、沟通协调能力以及追求卓越的技术精神。"
        }
    ],
    "total": 10
}
```